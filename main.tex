\documentclass[draft]{agujournal2019}
\usepackage{url} %this package should fix any errors with URLs in refs.
\usepackage{lineno}
%\usepackage[inline]{trackchanges} %for better track changes. finalnew option will compile document with changes incorporated.
\usepackage{soul}
\usepackage{gensymb}
\usepackage{placeins}
\usepackage{multirow}
\usepackage{setspace}
\usepackage{float}

\linenumbers
\linespread{1.25}

\draftfalse

\journalname{Water Resources Research}


\begin{document}


\title{Automated Input Variable Selection for Analog Methods Using Genetic Algorithms}

\authors{P. Horton\affil{1}, O. Martius\affil{1}, and S. L. Grimm\affil{2}}

\affiliation{1}{Institute of Geography, Oeschger Centre for Climate Change Research, University of Bern, Bern, Switzerland}
\affiliation{2}{Physikalisches Institut, University of Bern, Gesellschaftsstrasse 6, 3012 Bern, Switzerland}

\correspondingauthor{Pascal Horton}{pascal.horton@giub.unibe.ch}


\begin{keypoints}
\item Genetic algorithms were successful in selecting relevant input variables for the prediction of precipitation by analog methods
\item The analogy criteria were automatically selected, resulting in the discovery of a new promising criterion
\item The optimization resulted in a structure combining different predictors into a single level of analogy, while outperforming stepwise methods
\end{keypoints}


\begin{abstract}

Analog methods (AMs) have long been used for precipitation prediction and climate studies. However, they rely on manual selections of parameters, such as predictor variables and analogy criteria. Previous work showed the potential of genetic algorithms (GAs) to optimize most of the AM parameters. This research goes one step further and investigates the potential of GAs for automating the selection of the input variables and the analogy criteria (distance metric between two data fields) in AMs. Our study focuses on the prediction of daily precipitation in central Europe, specifically Switzerland, as a representative case.  
Comparative analysis against established methods demonstrates the superiority of GA-optimized AMs in terms of predictive accuracy. The selected input variables exhibit strong associations with key meteorological processes that influence the generation of precipitation. Further, we identify a new analogy criterion inspired by the Teweles-Wobus criterion, which consistently performs better than other Euclidean distances and could be used in classic AMs. In contrast to conventional stepwise selection approaches, GA-optimized AMs display a preference for a flatter structure characterized by a single level of analogy and an increased number of variables.
Overall, our study demonstrates the successful application of GAs in automating input variable selection for AMs, with potential implications for application in diverse locations and data exploration to predict alternative predictands. In a broader context, GAs could be used to perform input variable selection in other data-driven methods, opening perspectives for a broad range of applications.


\end{abstract}


\section{Introduction}

Analog methods (AMs) are statistical techniques grounded in the intrinsic connections between meteorological predictors, typically at a synoptic scale, and local weather patterns \cite{Lorenz1956, Lorenz1969}. AMs look for similar meteorological situations in the past to that of a target date of interest. They provide a conditional prediction based on the observed predictand values at these analog dates. Daily precipitation has often been the predictand of interest, either in the context of operational forecasting \cite<e.g.>[]{Hamill2006, Bliefernicht2010, Marty2012, Horton2012, Hamill2015, BenDaoud2016}, climate change studies \cite<e.g.>[]{Dayon2015, Raynaud2016b}, or past climate reconstruction \cite{Caillouet2016}. AMs are also used for other predictands, such as precipitation radar images \cite{Panziera2011, Foresti2015a}, temperature \cite{DelleMonache2013, Caillouet2016, Raynaud2016b, Jezequel2017}, wind \cite{DelleMonache2013, DelleMonache2011, Vanvyve2015, Alessandrini2015, Junk2015, Junk2015c}, and solar radiation or power production \cite{Alessandrini2015a, Bessa2015, Raynaud2016b}. Although deep learning methods nowadays become more and more popular in the context of forecasting, postprocessing and downscaling \cite<e.g.>[]{Chapman2022, Leinonen2020, Miralles2022, Otero2023}, AMs are still relevant and offer the benefit of interpretability.

Some AMs combine different predictors together using weights in the calculation of the distances between the target and the analog situations \cite<e.g.>[]{Keller2017, Meech2020}. Others may consist of a stepwise selection of similar meteorological situations based on multiple predictors organized in different consecutive levels of analogy, each of which conditions the subsequent selection. The similarity between two situations is computed using an analogy criterion (distance metric) over a relevant spatial domain. For each level of analogy, a certain number of analogs are selected \cite{Obled2002, Bontron2004}.

Stepwise AMs for predicting precipitation commonly have a first level of analogy based on the atmospheric circulation. The variable of interest is the geopotential height (Z) at various pressure levels and specific times throughout the day \cite<Table \ref{table:methods};>{Obled2002, Horton2018a}. \citeA{Bontron2004} introduced a second level of analogy based on a moisture index that is the product of the relative humidity at 850~hPa and the total precipitable water (RM3 method in Table \ref{table:methods}). Other consecutive studies selected different pressure levels \cite<>[method RM4 in Table \ref{table:methods}]{Horton2018a} or added a wind component to the moisture index \cite{Marty2010}. \citeA{BenDaoud2016} inserted an additional level of analogy between the circulation and the moisture analogy based on the vertical velocity at 850~hPa (methods RM6 in Table \ref{table:methods}) and named it "SANDHY" for Stepwise Analog Downscaling method for Hydrology \cite{BenDaoud2016, Caillouet2016}.

To calibrate the method, a semi-automatic sequential procedure \cite{Bontron2004, Radanovics2013, BenDaoud2016} has often been used to optimize the size of the domain and the number of analogs. However, predictor variables, vertical levels, temporal windows (time of day), and analogy criteria were manually selected. This manual selection requires the comparison of numerous combinations and a comprehensive assessment of some parameter ranges. Moreover, the sequential calibration procedure successively calibrates the different levels of analogy, and thus it does not handle parameters inter-dependencies. Considering these limitations, \citeA{Horton2017a} introduced a global optimization of the AM using genetic algorithms (GAs). Using this approach, an automatic and objective selection of the temporal windows, the vertical levels, the domains, and the number of analogs became possible, improving the prediction skills of the method \cite{Horton2018a}. A weighting of the predictor variables has also been introduced. The only parameters left for manual selection were the meteorological variables and the analogy criteria.

Selecting predictors for precipitation prediction with AMs in Europe has been the focus of multiple studies aiming to improve prediction skills \cite{Obled2002, Bontron2004, Gibergans-Baguena2007, Radanovics2013, BenDaoud2016}. Thus, the relevant predictors are likely to be known nowadays and supported by expert knowledge. However, transferring AMs to a region with different climatic conditions or to another predictand would involve reconsidering the selected meteorological variables. This work aims to test a fully automatic optimization of all AM parameters, including the selection of the meteorological variables and even the analogy criteria, using GAs. GAs have already been used for input variable selection (IVS) in other contexts \cite{Dheygere2003, Huang2007, Cateni2010, Gobeyn2017}.

GAs have also been used in the context of AMs for other tasks, such as the selection of optimal vertices in an unstructured grid approach to reduce computational resources when working with high-resolution data \cite{Hu2019}. An alternative approach to IVS, proposed by \citeA{Hu2023}, is to compress multiple predictors into latent features using a deep learning network and then select the analogs in this latent space. This approach eliminates the need for the prior selection of predictors; however, it sacrifices the advantage of interpretability provided by an analogy computed on the original variables.

Here, we seek to assess the potential of GAs for input variable selection in the context of the analog method. Moreover, we want to test the GAs' ability to jointly select the distance metric in addition, i.e., the analogy criterion. To compare with well-established AMs, daily precipitation in central Europe, specifically in Switzerland, has been chosen as predictand. Also, as is often the case, the AMs were optimized in the perfect prognosis framework, using predictors from reanalyses. This work focuses mainly on the proof of concept of automatic IVS for AMs rather than the details of the case study.

The paper is organized as follows. Section \ref{material_methods} describes the datasets, the fundamentals of AMs, the characteristics of the GAs implementation, the software used, and the details of the experiment setup. Section \ref{results} presents the results of different analyses, such as the selection of the best predictor variable, the relevance of various AM structures, and the accuracy of the optimized methods. Section \ref{discussion} discusses some findings of the work. Finally, section \ref{conclusions} summarizes the main contributions of the work and open perspectives for applications of the developed approach.


\section{Material and Methods}
\label{material_methods}

\subsection{Data}
\label{data}

The target variable (predictand) is daily precipitation derived from the RhiresD gridded dataset from \citeA{MeteoSwiss2021}. It is a daily aggregation (from 06~UTC of day D to 06~UTC of day D+1) at a 1~km resolution with data from 1961 onward. It is produced using an interpolation scheme between gauging stations \cite{Frei1998}. The gridded data were spatially aggregated across 25 catchments of about 200~km$^2$ (Table \ref{catchments}). These catchments were chosen to cover the different climatic regions of Switzerland \cite{Schuepp1980}, as illustrated in Fig.~\ref{map}.


\begin{figure}[hbt]
	\noindent\includegraphics[width=140mm]{figures/map.jpg}
	\caption{Location of the 25 selected catchments in Switzerland along with the climatic regions (dashed lines) and the river network (source: SwissTopo, HADES).}
	\label{map}
\end{figure}


\begin{table}[hbt]
	\centering
	\caption{Characteristics of the 25 selected catchments in Switzerland}
	\small
	\setstretch{0.8}
	\begin{tabular}{cllcc}
		\hline 
		Id & Name of the river & Climatic region & Area & Mean elevation \\
		& & & (km$^2$) & (m a.s.l.) \\
		\hline 
		1 & L'Allaine & Eastern Jura & 209.1 & 571 \\
		2 & Ergolz & Eastern Jura & 150.3 & 589 \\
		3 & L'Orbe & Western Jura & 209.3 & 1229 \\
		4 & La Birse & Western Jura & 203.3 & 920 \\
		5 & La Broye & Western Plateau & 184.5 & 791 \\
		6 & Murg & Central Plateau & 184.8 & 658 \\
		7 & Aabach & Central Plateau & 180.0 & 562 \\
		8 & T\"oss & Northeastern Plateau & 189.3 & 745 \\
		9 & Sense & Western alpine north slope & 179.6 & 1238 \\
		10 & La Sarine & Western alpine north slope & 200.8 & 1779 \\
		11 & Weisse L\"utschine & Western alpine north slope & 165.0 & 2149 \\
		12 & Emme & Central alpine north slope & 206.9 & 1151 \\
		13 & Engelberger Aa & Central alpine north slope & 204.3 & 1654 \\
		14 & Linth & Eastern alpine north slope & 195.7 & 1959 \\
		15 & Sitter & Eastern alpine north slope & 162.2 & 1069 \\
		16 & Dranse d'Entremont & Valais & 154.2 & 2340 \\
		17 & La Navisence & Valais & 210.5 & 2541 \\
		18 & Lonza & Valais & 161.7 & 2370 \\
		19 & Doveria & Southern Alps & 170.5 & 2241 \\
		20 & Ticino & Southern Alps & 208.5 & 2019 \\
		21 & Verzasca & Southern Alps & 187.4 & 1656 \\
		22 & Valser Rhein & North and Central Grisons & 185.8 & 2215 \\
		23 & Plessur & North and Central Grisons & 207.7 & 1928 \\
		24 & Mera & Southern Alps & 190.6 & 2142 \\
		25 & Flaz & Engadine & 193.1 & 2599 \\
		\hline 
	\end{tabular} 
	\label{catchments}
\end{table}

As is often done in the context of the perfect prognosis framework, we used variables provided by global reanalyses. Although most reanalysis provides good quality data in Europe, differences still exist, and the choice of the reanalysis dataset can impact the accuracy of the AM even more substantially than the choice of the predictor variables \cite{Horton2018b}. Thus, it was considered advisable to test some of the following analyses with another reanalysis to assess the robustness of the selected variables.

The main reanalysis used in this work is ERA-Interim \cite<ERA-I,>{Dee2011a}, which was produced by the European Centre for Medium-Range Weather Forecasts (ECMWF) and covers the period from 1979 to 2019. The forecast model uses a hybrid sigma-pressure vertical coordinate on 60 layers and has a T255 horizontal resolution (about 79~km) and a 30~min time step. The output variables have a grid resolution of 0.75\degree. This work started before the release of ERA5, the successor of ERA-I.

The Climate Forecast System Reanalysis \cite<CFSR,>{Saha2010a}, provided by NCEP, was used for the first experiment to compare the results obtained with ERA-I. The model used to produce CFSR has a horizontal resolution of T382 (about 38~km) and 64 levels on sigma-pressure hybrid vertical coordinates. The period covered is 1979 to August 2019, and the output variables have a spatial resolution of 0.5\degree.

Finally, ERA5 \cite{Hersbach2019} was used for the last analysis. ERA5 provides more variables and a higher spatial (0.25\degree, but used here at 0.5\degree) and temporal resolution (hourly, but used here at a 3-hourly time step). ERA5 assimilates considerably more data than ERA-I and provides, among others, more consistent sea surface temperature and sea ice, improved representation of tropical cyclones, better balance of evaporation and precipitation, and improved soil moisture. ERA5 also relies on more appropriate radiative forcing and boundary conditions (e.g., changes in greenhouse gases, aerosols, SST, and sea ice) \cite{Hersbach2019}.


\subsection{Analog Methods}
\label{ams}

AMs are based on the rationale that two similar synoptic situations may produce similar local weather \cite{Lorenz1956, Lorenz1969}. It thus consists of extracting past atmospheric situations similar to a target date. Selected predictor fields define this similarity. The analogy is defined by:

\begin{enumerate}		
	\item The selected meteorological variables (predictors).
	\item The vertical levels at which the predictors are selected.
	\item The spatial windows (domains) over which the predictors are compared.
	\item The hours of the day at which the predictors are considered.
	\item The analogy criteria (distance metric to rank candidate situations).
	\item Possible weights between the predictors.
	\item The number of analog situations $N_{i}$ to select for the level of analogy $i$.
\end{enumerate}

AMs usually start with a seasonal preselection to cope with seasonal effects \cite{Lorenz1969}. The seasonal preselection is often implemented as a moving window of 120~days centered around the target date \cite{Bontron2004, Marty2012, Horton2012, BenDaoud2016}. Alternatively, the candidate dates can be preselected based on similar air temperatures at the nearest grid point \cite[methods RM5 and RM6 in Table \ref{table:methods}]{BenDaoud2016}. In this work, we used the temporal moving window to reduce the number of potential candidate dates and, thus, the computing time.


\begin{table}[hbt]
	\caption{Some analog methods listed by increasing complexity. The analogy criterion is $S_{1}$ for Z and RMSD for the other variables. The predictors are described by meteorological variables (e.g., Z), pressure levels (e.g., 1000), and time windows (e.g., 12h UTC). Multiple time steps can be considered. For example, 'MI850@12+24h' indicates that the moisture index is being considered at 12h and 24h UTC. In the case of 'W850@06-24h', all 6-hourly time steps between 6h and 24h UTC are being used.}
	\small
	\setstretch{0.8}
	\begin{tabular}{llllll}
		\hline
		\textbf{Method} & \textbf{Preselection} & \textbf{First level} & \textbf{Second level} & \textbf{Third level} & \textbf{Reference} \\ 
		\hline 
		\multirow{2}{*}{\textbf{RM1}} & \multirow{2}{*}{$\pm 60$ days} & Z1000@12h &&& \multirow{2}{*}{\citeA{Bontron2004}} \\
		&& Z500@24h &&& \\
		\hline 
		\multirow{4}{*}{\textbf{RM2}} & \multirow{4}{*}{$\pm 60$ days} & Z1000@06h &&& \multirow{4}{*}{\citeA{Horton2018a}} \\
		&& Z1000@30h &&& \\
		&& Z700@24h &&& \\
		&& Z500@12h &&& \\
		\hline 
		\multirow{2}{*}{\textbf{RM3}} & \multirow{2}{*}{$\pm 60$ days} & Z1000@12h & \multirow{2}{*}{MI850@12+24h} && \multirow{2}{*}{\citeA{Bontron2004}} \\
		&& Z500@24h &&& \\
		\hline 
		\multirow{4}{*}{\textbf{RM4}} & \multirow{4}{*}{$\pm 60$ days} & Z1000@30h &&& \multirow{4}{*}{\citeA{Horton2018a}}\\
		&& Z850@12h & MI700@24h && \\
		&& Z700@24h & MI600@12h && \\
		&& Z400@12h &&& \\
		\hline 
		\multirow{2}{*}{\textbf{RM5}} & T925@36h & Z1000@12h & MI925@12+24h && \multirow{2}{*}{\citeA{BenDaoud2016}} \\
		& T600@12h & Z500@24h & MI700@12+24h && \\
		\hline 
		\multirow{2}{*}{\textbf{RM6}} & T925@36h & Z1000@12h & \multirow{2}{*}{W850@06-24h} & MI925@12+24h & \multirow{2}{*}{\citeA{BenDaoud2016}} \\
		& T600@12h & Z500@24h && MI700@12+24h & \\
		\hline 
		\multicolumn{6}{l}{Z, geopotential height; T, air temperature; W, vertical velocity; MI, moisture index.}
	\end{tabular} 
	\label{table:methods}
\end{table}

The first level of analogy in AMs for precipitation is often based on the atmospheric circulation using the geopotential height (Z) at different pressure levels and hours of the day (Table \ref{table:methods}). The distance (analogy criterion) between two Z fields is calculated on the vector components of the gradient, i.e., using the difference between adjacent grid cells, rather than comparing absolute values. The Teweles--Wobus criterion \cite<$S_{1}$, Eq. \ref{eq:S1},>{Teweles1954, Drosdowsky2003} was identified as the most suitable by different studies \cite{Wilson1980, Woodcock1980, Guilbaud1998, Bontron2004}. It is defined as follows:

\begin{equation}
	\label{eq:S1}
	S_{1}=100 \frac {
        \displaystyle \sum_{i} 
            \vert \Delta\hat{z}_{i} - 
            \Delta z_{i} \vert
    }
	{
        \displaystyle \sum_{i} \max\left\lbrace 
            \vert \Delta\hat{z}_{i} \vert , 
            \vert \Delta z_{i} \vert \right
        \rbrace 
    }
\end{equation}
where $\Delta \hat{z}_{i}$ is the gradient component between the \textit{i}th pair of adjacent points from the geopotential field of the target situation, and $\Delta z_{i}$ is the corresponding gradient component in the candidate situation. The gradient components are computed in both the latitude and longitude directions. $S_{1}$ ranges from 0 to 200. The smaller the $S_{1}$ values, the more similar the shape of the pressure fields and therefore the atmospheric circulation. $S_{1}$ was developed to verify prognostic charts \cite{Teweles1954}. It was computed using pressure differences between stations arranged in north-south and east-west lines. The "difficulty coefficient" (the denominator) reduces the influence of the seasons and the strength of the weather systems on the score.

After selecting a certain number of analog dates based on Z, subsequent steps can be added to subsample a lower number of analog situations based on other predictors. The method developed by \citeA{BenDaoud2016} has, for example, three levels of analogy (and a preliminary level for the preselection) where each level subselects a smaller number of analog situations from the candidates provided by the previous level (RM6 method in Table \ref{table:methods}). For other predictors than the geopotential height (e.g., for moisture variables), classic criteria representing Euclidean distances between grid point values are used.

The output of the AM is a probabilistic prediction for the target day. It is provided by the empirical conditional distribution of the $N_{i}$ predictand values corresponding to the $N_{i}$ dates selected at the last level of analogy.


\subsection{Genetic Algorithms}
\label{gas}

Genetic Algorithm (GA) is a global optimization technique inspired by genetics and natural selection \cite{Holland1992b}. It belongs to the family of evolutionary algorithms and comprises different operators such as natural selection, couples selection, chromosome crossover, mutation, and elitism. These operators act on parameter sets of the problem to optimize by mixing, combinations, and random modifications. GA aims to combine, over time, the strength of different parameter sets and to explore the parameter space while converging toward the global optimum. The optimization starts here with 2000 random parameter sets (as defined in Sect. \ref{ams}) and is stopped when the best parameter set cannot be improved after 30~iterations.

A variant of GA has been tailored to optimize AMs by \citeA{Horton2017a}. All the parameters of the method, except the meteorological predictor variables and the analogy criteria, have already been successfully optimized using GAs \cite{Horton2018a}. All parameters were optimized jointly on the different levels of analogy. The use of GAs provided for the first time an objective and global optimization of AMs, resulting in gains in prediction accuracy. To bring the optimization further, the selection of the predictor variables and the analogy criteria were performed here by GAs.

The reason why the predictor variables and analogy criteria were left out in the previous GA-AM setup by \citeA{Horton2017a} is the different nature of these variables. The parameters optimized so far by \citeA{Horton2017a} were quantitative variables, that is, numerical values (e.g. location and size of the spatial windows or the number of analogs), which have a notion of continuity. However, the parameters characterizing the selected predictors or analogy criteria are entries in a list of possible variables/criteria that can be considered as categorical variables as there is no relationship among entries. They are treated as arrays of independent values by the algorithm. Therefore, the mutation operator relying on a search radius in the parameter space \cite{Horton2017a} cannot be applied. Instead, a simple random sampling was used for these parameters when selected for mutation. In addition to the increased difficulty due to the higher number of parameters to optimize, this aspect will likely slow down the optimization.

In GAs, the mutation operator changes a parameter value (gene) if this parameter was selected to mutate (all parameters have a certain mutation probability). The new value assigned depends on the rules of the mutation operator applied. This operator enables the optimization to explore new areas of the parameter space and was shown to have the greatest impact on the success of AM optimizations \cite{Horton2017a}. Thus, as suggested in \citeA{Horton2017a}, five variants of this operator were used in parallel optimizations (see details in Appendix B): three variants of the non-uniform mutation \cite{Michalewicz1996}, the multiscale mutation, and the chromosome of adaptive search radius. The non-uniform mutation aims to reduce the magnitude of the search in the parameter space with the evolution of the population to transition from the exploration of the whole parameter space to the exploitation of local solutions. This operator has three controlling variables, which makes it difficult to adjust, and thus is used with three different configurations. The multiscale mutation considers both exploration and exploitation in parallel. It has no controlling parameters and no evolution during the optimization. The chromosome of adaptive search radius was introduced by \citeA{Horton2017a} and is inspired by the non-uniform mutation. It takes an auto-adaptive approach by adding two chromosomes, one for the mutation rate and one for controlling the search magnitude \cite<see details in>{Horton2017a}. Therefore, it has no controlling parameters, is thus easier to use, and automatically transitions from the exploration phase to exploitation.


\subsection{Software}
\label{software}

The optimization of AMs with GAs is implemented in the open-source AtmoSwing software\footnote{https://atmoswing.org/} \cite{Horton2019} that has been used for this work. AtmoSwing is written in object-oriented C++ and has been optimized for computational performance. It scales well on HPC infrastructures, as the different members of the GAs populations, i.e., the various parameter sets, can be assessed in parallel using multiple independent threads. However, due to the increasingly large number of assessments needed by GAs with the increasing complexity of the problem, a further reduction in computing time became necessary. Indeed, while applying AMs to perform a prediction for a single target date is a very fast and light process, GAs require a substantial amount of parameter assessments over long calibration periods.

Despite being simple methods, AMs require many comparisons of gridded fields during the calibration phase. For example, this work used a 24-year calibration period. For each target day, a gridded predictor needs to be compared to about 2820 candidate situations (24*120-60, using a 120-day temporal window minus 60 days in the target year that are excluded). Over the entire calibration period, this amounts to about $2.47\cdot10^7$ (24*365*2820) field comparisons per predictor of the first level of analogy. Here, one optimization required, on average, about 200 generations made of 2000 individuals, which brings the average number of grid comparisons to about $1\cdot10^{13}$ per predictor of the first level of analogy. The comparison of the gridded predictors –- i.e., the calculation of the analogy criteria -- was identified by profilers as the most time-consuming task, despite using the efficient linear algebra library Eigen 3 \cite{Guennebaud2010}.

A first attempt to reduce the computing time was based on storing the whole history of the optimization in memory and looking up for similar already-assessed parameters to a newly generated parameter set. However, this approach turned out to be even more time-consuming after several generations and led to memory issues for long optimizations. Finally, computation using graphics processing units (GPUs) was implemented for this study in a new version of AtmoSwing, v.2.1.2 \cite{Horton2019b}. The calculation of the analogy criteria has been written using NVIDIA's CUDA. The details of the implementation and the results of a benchmark experiment can be found in Appendix A. When optimizing the methods using ERA5 at a 3-hourly time step and 0.5\degree\ resolution, the difference is substantial. One generation (2000 evaluations) took 8 to more than 10 hours using 20 CPU threads, while 50 to 80 minutes were needed using 3 CPU threads and 3 GPU devices (NVIDIA GeForce703 RTX 2080).


\subsection{Experimental Setup}
\label{setup}

The experiments were carried out over a 30-year period, from 1981 to 2010, divided into a calibration period (CP) and an independent validation period (VP). An additional test period (TP), covering the years 2011 to 2017, was allocated to evaluate the accuracy of the optimized methods on unseen data (Sect. \ref{skill_score}). To reduce the impact of potential inhomogeneities in the time series, the selection of the validation period (VP) was evenly distributed over the entire series \cite<as in>[]{BenDaoud2010}. A total of 6 years was used for the VP by selecting one year out of every five (explicitly: 1985, 1990, 1995, 2000, 2005, 2010). The archive period (AP), where the analog dates are being retrieved, is the same as the CP. The VP is also excluded from the AP (days from the VP were never used as candidate situations for the selection of analogs), as well as a period of $\pm30$ days around the target date to exclude potential dependent meteorological situations. Unless stated otherwise, all results are presented for the VP.

The GAs optimized all parameters of the method. Only the AM structure (number of analogy levels and predictors) was not optimized. Different structures were tested in section \ref{structures}. For each level of analogy and each predictor, the following parameters were optimized within the corresponding ranges:

\begin{enumerate}		
	\item Meteorological variable: see section \ref{variables}.
	\item Vertical level: see section \ref{variables}.
	\item Temporal windows (time of the day): from day D 00~UTC to D+1 06~UTC (c.f. precipitation accumulation period, sect \ref{data})
	\item Spatial window (domain): latitudes=[35, 55], longitudes=[-10, 20]. The spatial windows differ between predictors, even within the same level of analogy.
	\item Analogy criterion: see section \ref{criteria}.
	\item Weight: [0, 1] with a precision of 0.01 (0.05 for experiment 2). The optimizer can turn off a variable by setting its weight to zero.
	\item Number of analogs: varies according to the structure, but with an overall range of [5, 300] and a step of 5. The optimizer can turn off a level of analogy by setting its number of analogs to the same value as the previous level of analogy.
\end{enumerate}

The CRPS \cite<Continuous Ranked Probability Score;>{Brown1974, Matheson1976, Hersbach2000} was used to assess the accuracy of the predictions and is the objective function used by the GAs. It evaluates the predicted cumulative distribution functions $F(y)$, here of the precipitation values $y$ associated with the analog situations, compared to the single observed value $y^{0}$ for a day $i$:

\begin{equation}
	\label{eq:CRPS}
	CRPS_{i} = \int_{0}^{+\infty} \left[ 
        F_{i}(y)-H_{i}(y-y_{i}^{0})
    \right]^{2} dy,
\end{equation}
where $H(y-y_{i}^{0})$ is the Heaviside function that is null when $y-y_{i}^{0}<0$, and 1 otherwise; the better the prediction, the lower the score. The CRPS was here computed using the rectangle approximation based on the discrete precipitation values provided by the analog dates.


\subsubsection{Meteorological Variables}
\label{variables}

The meteorological variables were considered for different types of vertical levels: surface or entire atmosphere (to capture, for example, the moisture content of an entire air column), pressure levels (1000, 950, 900, 850, 800, 700, 600, 500, 400, 300, 200~hPa, to capture the vertical structure), potential temperature levels (290, 300, 310, 320, 330, 350, 400~K, necessary to include potential vorticity), and potential vorticity levels. The selected variables are listed in Table \ref{list_variables}. The optimization can pick any variable on any level type and value, as long as it is available. Precipitation variables from reanalyses were not considered potential predictors. Precipitation is often considered as a predictor in AMs used in a post-processing context (where the same precipitation product is used for training and then predicting). However, AMs targeting downscaling tasks or alternative forecasts to NWP models do not rely on precipitation, as a method developed in the perfect prognosis context (using reanalyses datasets that can potentially assimilate precipitation data) would then be difficult to use in other contexts (using other model outputs) due to the high uncertainties and the biases associated with precipitation predicted by an NWP or a climate model.

The variables were standardized (using the overall climatology) on-the-fly by AtmoSwing when loaded from files. Standardization has no impact on the selection of analog situations for a single predictor, but it makes the combination of predictors within one level of analogy more balanced, as they might have very different orders of magnitude and units. It allows for a more effective optimization of the weights between predictors.

\begin{table}[!htbp]
	\caption{Selected variables for ERA-I, CFSR, and ERA5 for different types of vertical levels.}
	\small
	\setstretch{0.8}
	\noindent\makebox[\textwidth]{
	\begin{tabular}{lll|cccc|cccc|cc}
		\hline 
		Variable & Id & Unit &  &  \multicolumn{2}{c}{\textbf{ERA-I}}  &  &  &  \multicolumn{2}{c}{\textbf{CFSR}}  &  &  \multicolumn{2}{c}{\textbf{ERA5}}   \\
		&  & \multicolumn{1}{r|}{Levels:} & PL & PT & PV & SC & PL & PT & PV & SC & PL & SC \\
		\hline 
		\multicolumn{3}{l|}{\uppercase{Circulation variables}}  & & & & & & & & & & \\
		\ Geopotential height & Z & gpm & $\bullet$ &  & $\bullet$ &  & $\bullet$ &  & $\bullet$ & $\bullet$ & $\bullet$ & \\
		\ Geopotential height anomaly & ZA & gpm &  &  &  &  & $\bullet$ &  &  &  & & \\
		\ Zonal wind & U & m s$^{-1}$ & $\bullet$ & $\bullet$ & $\bullet$ &   $^{\ }\bullet^{a}$ & $\bullet$ & $\bullet$ & $\bullet$ &  & $\bullet$ & $^{\ }\bullet^{a}$ \\
		\ Meridional wind & V & m s$^{-1}$ & $\bullet$ & $\bullet$ & $\bullet$ &   $^{\ }\bullet^{a}$ & $\bullet$ & $\bullet$ & $\bullet$ &  & $\bullet$ & $^{\ }\bullet^{a}$ \\
		\ Pressure & PRES & Pa &  & $\bullet$ & $\bullet$ &   $^{\ }\bullet^{c}$ &  &  & $\bullet$ &  $\bullet\bullet^{c}$ & & $^{\ }\bullet^{c}$ \\
		\ Vertical velocity & W & Pa s$^{-1}$ & $\bullet$ & $\bullet$ &  &  & $\bullet$ & $\bullet$ &  &  & $\bullet$ & \\
		\ Divergence & D & s$^{-1}$ & $\bullet$ & $\bullet$ &  &  &  &  &  &  & $\bullet$ & \\
		\ Vorticity & VO & s$^{-1}$ & $\bullet$ &  &  &  & $\bullet$ &  &  &  & & \\
		\ Potential vorticity  & PV & m$^{2}$ s$^{-1}$ K kg$^{-1}$ & $\bullet$ & $\bullet$ &  &  &  & $\bullet$ &  &  & $\bullet$ & \\
		\ Stream function & STRM & m$^{2}$ s$^{-1}$ &  &  &  &  & $\bullet$ &  &  &  & & \\
		\ Velocity potential & VPOT & m$^{2}$ s$^{-1}$ &  &  &  &  & $\bullet$ &  &  & & &  \\
		\ Montgomery potential & MONT & m$^{2}$ s$^{-2}$ &  & $\bullet$ &  &  &  &  &  & & & \\
		\ Montgomery stream function & MNTSF & m$^{2}$ s$^{-1}$ &  &  &  &  &  & $\bullet$ &  &  & & \\
		\hline
		\multicolumn{3}{l|}{\uppercase{Moisture variables}} & & & & & & & & & & \\
		\ Relative humidity & RH & \% & $\bullet$ &  &  &  & $\bullet$ & $\bullet$ &  & $\bullet$ & $\bullet$ & \\
		\ Specific humidity & SH & kg kg$^{-1}$ & $\bullet$ & $\bullet$ &  &  & $\bullet$ &  &  & & &  \\
		\ Total column water & TCW & kg m$^{-2}$ &  &  &  & $\bullet$ &  &  &  &  & & $\bullet$\\
		\ Total column water vapour & TCWV & kg m$^{-2}$ &  &  &  & $\bullet$ &  &  &  & $\bullet$ & & \\
		\ Cloud water & CWAT & kg m$^{-2}$ &  &  &  &  &  &  &  & $\bullet$ & & \\
		\ Surface moisture flux & IE & kg m$^{-2}$ s$^{-1}$ &  &  &  & $\bullet$ &  &  &  &  & & \\
		\hline
		\multicolumn{3}{l|}{\uppercase{Temperature variables}} & & & & & & & & & & \\
		\ Temperature & T & K & $\bullet$ &  &  & $^{\ }\bullet^{b}$ & $\bullet$ & $\bullet$ & $\bullet$ &  & $\bullet$ & $^{\ }\bullet^{b}$ \\
		\ Potential temperature & PT & K &  &  & $\bullet$ &  &  &  &  &  & & \\
		\ Dewpoint temperature* & DT & K &  &  &  & $^{\ }\bullet^{a}$ &  &  &  &  & & \\
		\ Sea surface temperature & SST & K &  &  &  & $\bullet$ &  &  &  & & &  \\
		\ 0$\degree$ C isothermal level & DEG0L & m &  &  &  & $\bullet$ &  &  &  & & & $\bullet$ \\
		\hline
		\multicolumn{3}{l|}{\uppercase{Radiation variables}} & & & & & & & & & & \\
		\ Surf. net solar radiation & SSR & J m$^{-2}$ &  &  &  & $\bullet$ &  &  &  & & & $\bullet$ \\
		\ Surf. solar rad. downwards & SSRD & J m$^{-2}$ &  &  &  & $\bullet$ &  &  &  & & & $\bullet$ \\
		\ Surf. net thermal radiation & STR & J m$^{-2}$ &  &  &  & $\bullet$ &  &  &  & & & $\bullet$ \\
		\ Surf. thermal rad. downwards & STRD & J m$^{-2}$ &  &  &  & $\bullet$ &  &  &  & & & $\bullet$ \\
		\ Surf. latent heat flux & SLHF & J m$^{-2}$ &  &  &  &  &  &  &  & & & $\bullet$ \\
		\ Surf. sensible heat flux & SSHF & J m$^{-2}$ &  &  &  &  &  &  &  & & & $\bullet$ \\
		\ Top net solar radiation & TSR & J m$^{-2}$ &  &  &  &  &  &  &  & & & $\bullet$ \\
		\ Top net thermal radiation & TTR & J m$^{-2}$ &  &  &  &  &  &  &  & & & $\bullet$ \\
		\hline
		\multicolumn{3}{l|}{\uppercase{Stability indices}} & & & & & & & & & & \\
		\ Convective avail. pot. energy & CAPE & J kg$^{-1}$ &  &  &  & $\bullet$ &  &  &  & $\bullet$ & & $\bullet$ \\
		\ Convective inhibition & CIN & J kg$^{-1}$ &  &  &  &  &  &  &  & $\bullet$ & & $\bullet$ \\
		\ Best (4 layer) lifted index & 4LFTX & K &  &  &  &  &  &  &  & $\bullet$ & & \\
		\ Surface lifted index & LFTX & K &  &  &  &  &  &  &  & $\bullet$ & & \\
		\ Lapse rate & LAPR & K m$^{-1}$ &  &  &  &  &  & $\bullet$ &  &  & & \\
		\hline
		\multicolumn{3}{l|}{\uppercase{Others}} & & & & & & & & & & \\
		\ Cloud cover & CC & (0 - 1) &  &  &  &  &  &  &  &  & $\bullet$ & \\
		\ Low cloud cover & LCC & (0 - 1) &  &  &  &  &  &  &  &  & & $\bullet$ \\
		\ Total cloud cover & TCC & (0 - 1) &  &  &  &  &  &  &  &  &  & $\bullet$ \\
		\ Snow depth & SD & m of w.e. &  &  &  & $\bullet$ &  &  &  &  & & \\
		\hline
		\multicolumn{13}{l}{PL = pressure levels, PT = pot. temp. levels, PV = pot. vorticity levels, SC = single level, surface, or total column} \\
		\multicolumn{13}{l}{*moisture and temperature variable, $^{a}$at 10~m, $^{b}$at 2~m, $^{c}$at mean sea level.}\\
		\hline 
	\end{tabular}}
	\label{list_variables}
\end{table}


\subsubsection{Analogy Criteria}
\label{criteria}

During the optimization, the GAs can select different analogy criteria for the different predictors, with the aim of identifying the best criteria per predictor. These are then combined using weights to provide a single analogy distance value. The most common analogy criteria in AMs are the Root Mean Square Deviation (RMSD) and the Teweles--Wobus criterion ($S_{1}$, see section \ref{ams}). Other criteria were made available to the GAs in order to explore potential new characterizations of the analogy metrics. Two of these criteria are new and are derived from S1. The potential criteria made available to the GAs are the following:

\begin{enumerate}
	\item RMSD: the Root Mean Square Deviation.
	\item MD: the Mean Absolute Difference, or Mean Absolute Error. It differs from the RMSD in that the differences are not squared.
	\item $S_{1}$: the Teweles--Wobus index as defined in Eq. \ref{eq:S1} from section \ref{ams}. It consists of a comparison of the gradients, mainly used for the geopotential height.
	\item $S_{2}$: inspired by the Teweles--Wobus index, we introduced a new criterion based on the second derivative of the fields instead of the gradients:
	\begin{equation}
		\label{eq:S2}
		S_{2}=100 \frac {\displaystyle 
            \sum_{i} \vert \nabla^{2}\hat{x}_{i} - 
            \nabla^{2} x_{i} \vert
        }
		{\displaystyle 
            \sum_{i} \max\left\lbrace 
                \vert \nabla^{2}\hat{x}_{i} \vert , 
                \vert \nabla^{2} x_{i} \vert 
            \right\rbrace 
        }
	\end{equation}
	where $\nabla^{2} \hat{x}_{i}$ is the second derivative between the \textit{i}th triplet of adjacent points from the predictor field of the target situation, and $\nabla^{2} x_{i}$ is the corresponding second derivative in the candidate situation.
 Please note that it differs from the $S_{2}$ index from \citeA{Teweles1954}.
	\item $S_{0}$: as with $S_{2}$, this new criterion is derived from $S_{1}$ and is processed on the raw grid values. It differs from the MD mainly in that it is normalized by the sum of the maximum values instead of the number of points:
	\begin{equation}
		\label{eq:S0}
		S_{0}=100 \frac {\displaystyle 
            \sum_{i} \vert \hat{x}_{i} - 
            x_{i} \vert
        }
		{\displaystyle 
            \sum_{i} \max\left\lbrace 
                \vert \hat{x}_{i} \vert , 
                \vert x_{i} \vert 
            \right\rbrace 
        }
	\end{equation}
	where $\hat{x}_{i}$ is the \textit{i}th point from the predictor field of the target situation, and $x_{i}$ is the corresponding point in the candidate situation. The reason for adding such a criterion was accidental, as it was an erroneous implementation of $S_{2}$. However, it turned out to be relevant (see sections \ref{results} and \ref{discussion}).
	\item DSD: difference in standard deviation over the spatial window. It is a non-spatial criterion, as the location of the features does not matter.
	\item DMV: absolute difference in mean value. It is also non-spatial, as the means are computed over the spatial window before comparison.
\end{enumerate}

\subsubsection{Design of Experiments}
\label{experiments}

The input variable selection with GAs has been assessed in sequential steps. First, GAs were used to identify the single best predictor variables and their associated analogy criteria for each catchment (Sect. \ref{best_single}). The objective was to assess the consistency of the selected variables in the most straightforward configuration. Then, since AMs can be made of different levels of analogy with multiple predictors, the second experiment assessed the accuracy associated with different structures and the ability of GAs to deal with these, using a limited number of catchments (Sect. \ref{structures}). Based on these results, the third experiment performed the input variable selection for each catchment (Sect \ref{best_multi}). For all experiments, the GAs used the CRPS of the precipitation prediction as the objective function. The selection of the meteorological variables and the analogy criteria, along with the other parameters, is thus done to improve the accuracy of the AM.


\section{Results}
\label{results}

\subsection{Best Single Variables}
\label{best_single}

The first experiment evaluates the use of GAs to select a single predictor variable and analogy criterion for each catchment. The selection has been performed using ERA-I (Fig. \ref{fig_best_era_int}) but also CFSR for comparison (Fig. \ref{fig_best_cfsr}), with six optimizations per catchment and dataset. The six optimizations were based on different mutation operators (the five variants but twice the chromosome of adaptive search radius). The purpose of using two reanalyses is to assess the consistency and possible differences in the variable selection between two datasets.

One of the first elements that can be seen for both datasets is the dominance of the $S_{0}$ criterion, selected 60\% of the time for ERA-I and more than 55\% of the time for CFSR, along with the other criteria based on Teweles--Wobus (Fig. \ref{fig_criteria}). The other analogy criteria were rarely selected, if at all. The same applies to the RMSD, commonly used in analog methods. The GAs could better predict using $S_{0}$ as a metric for the Euclidian distance between the predictor fields. This result is further discussed in Sect. \ref{discussion}.

\begin{figure}[hbt]
	\noindent\makebox[\textwidth]{
		\includegraphics[width=170mm]{figures/single-variables-ERA-I.pdf}
	}
	\caption{Best single variable selected (ordinate; see Table \ref{list_variables} for the variables abbreviations) from ERA-I for the 25 catchments (abscissa). The colors represent the analogy criteria, and the size of the dots is proportional to the accuracy of the resulting method (the larger the dots, the better), within a range of 5\% of the best result (those with lower accuracy are hidden).}
	\label{fig_best_era_int}
\end{figure}

\begin{figure}[hbt]
	\noindent\makebox[\textwidth]{
		\includegraphics[width=170mm]{figures/single-variables-CFSR.pdf}
	}
	\caption{Same as Fig. \ref{fig_best_era_int} but for CFSR.}
	\label{fig_best_cfsr}
\end{figure}

\begin{figure}[hbt]
	\noindent\makebox[\textwidth]{
		\includegraphics[width=90mm]{figures/criteria.pdf}
	}
	\caption{Frequency of the criteria selection for both reanalysis datasets.}
	\label{fig_criteria}
\end{figure}

\begin{figure}[hbt]
	\noindent\makebox[\textwidth]{
		\includegraphics[width=130mm]{figures/map-variables.pdf}
	}
	\caption{Map of the best variables for ERA-I for each catchment.}
	\label{fig_map_variables}
\end{figure}

The variable selection results show some variability per catchment but similar accuracy. Although GAs can, in theory, identify the global optimum, this search is highly time consuming for such complex problems, and we have to stop the optimizations at a good-enough solution. These factors explain the variability that can be observed in the results. Nevertheless, this variability provides information about alternative variables with almost the same predictive accuracy.

Figures \ref{fig_best_era_int} and \ref{fig_best_cfsr} demonstrate that the optimal variables can vary across different regions. Figure \ref{fig_map_variables} illustrates this information spatially for the ERA-I variables. In terms of similarities, the vertical velocity (W) at 700 and 800~hPa is the most frequently selected for both data sets and is quantified using the $S_{0}$ criteria. Upward vertical winds at these levels are typically associated with precipitation generation. Within the southern Alpine climatic region (catchments 19, 20, 21), Z (based on the $S_{1}$ criterion) emerges as the best single predictor for ERA-I, which is not so clear with CFSR. Heavy precipitation events in this region are primarily the result of orographic effects related to sustained southerly advection of moisture-laden air masses \cite{Massacand1998}. Other regional clusters can be observed using ERA-I, such as the meridional wind V (with $S_{1}$) in the eastern part of Switzerland, also likely related to the southerly advection, STR(D) (surface net thermal radiation and surface thermal radiation downwards) in northern Switzerland (see the discussion in Sect. \ref{discussion}), and the second derivative of Z (with $S_{2}$) for several catchments at similar latitudes. The second derivative of Z is also frequently selected for CFSR. While cloud water (CWAT) is often chosen from CFSR, it is not available directly in ERA-I.


\subsection{Assessment of AM Structures}
\label{structures}

The analysis of different AM structures (Sect. \ref{experiments}) aims to identify the best performing structures, i.e., the optimal number of analogy levels and predictors. We first considered one to four levels of analogy, with one to four predictors per level. Five optimizations were performed for each of these 16 structures with the different mutation operators. As this assessment requires 80~optimizations, it was performed on only four catchments (L'Allaine (1), Sitter (15), Doveria (19), Flaz (25)). These were selected to maximize the diversity of climatic conditions represented. A complementary analysis was performed on two catchments (L'Allaine (1) and Doveria (19)) to explore the use of up to eight predictors on one and two levels of analogy. These experiments also allowed comparing the performance of the mutation operators for different problem complexities.

Even though the structure is provided to the GAs, it can still evolve to a simpler version by assigning a zero weight to some predictors or by setting the same number of analogs for two successive levels of analogy. This simplification often happened, such as that no solution ended up with the structure 4~x~4 (four levels of analogy with four predictors each). The best performing methods in the validation period were always made of one or two levels of analogy (Fig. \ref{fig_structures_a} and \ref{fig_structures_b}). Although some AMs have up to four levels of analogy (Sect. \ref{ams}), the use of normalized variables and weights might here favor their combination in the same level of analogy. Methods with fewer levels of analogy present less of a hierarchy among the predictors. However, not having a systematic constraint by the atmospheric circulation, as in most AMs, results in more influence from other variables. Although atmospheric circulation is often of primary importance for heavy precipitation events, there may be situations where it is preferable to relax these constraints. Nevertheless, we cannot conclude that two levels of analogy are the maximum to be considered, as the optimizer might have failed to optimize complex structures satisfactorily.

\begin{figure}[hbt]
	\noindent\makebox[\textwidth]{
		\includegraphics[width=110mm]{figures/ams-structures-a.pdf}
	}
	\caption{CRPS scores obtained for different AM structures with up to four levels of analogy and four variables per level for four catchments in Switzerland. Lower CRPS (yellow) represents a better accuracy. Five optimizations were started for each structure. The numbers inside the cells show the optimizations that ended with the given structure. The numbers in parenthesis illustrate the number of optimizations gained by a simplification of an initially more complex structure (positive values) or lost in favour of simpler structures (negative values).}
	\label{fig_structures_a}
\end{figure}

\begin{figure}[hbt]
	\noindent\makebox[\textwidth]{
		\includegraphics[width=110mm]{figures/ams-structures-b.pdf}
	}
	\caption{Same as Fig. \ref{fig_structures_a} for different AM structures with up to two levels of analogy and eight variables per level for two catchments in Switzerland.}
	\label{fig_structures_b}
\end{figure}

The results also show notable performance differences between the mutation operators (Sect. \ref{gas}). The chromosome of adaptive search radius (option \#1) provides the best performing parameter sets 76.3\% of the time for the calibration period and 62.5\% of the time for the validation period (Fig. \ref{fig_mutation_operators_perfs}). The second best is the non-uniform mutation with a mutation probability ($p_{mut}$) of 0.1 (option \#4), which is the best option for 11.3\% of the optimizations for the calibration period and 21.3\% for the validation period. However, the same operator with a mutation probability ($p_{mut}$) of 0.2 (option \#5; $G_{m,r}$=100) is the worst-performing option, with a success rate of 1.3\% for the calibration period and 2.5\% for the validation period. It quite well illustrates the difficulty of tuning such operators and the risk of a badly-configured mutation operator, and thus the benefit of an auto-adaptive option such as the chromosome of adaptive search radius with no controlling parameters. Moreover, the latter usually performed better for more complex AM structures.

\FloatBarrier

\subsection{Full Optimization}
\label{best_multi}

The third experiment used different AM structures to perform the full input variable selection for each catchment. Only the chromosome of adaptive search radius has been used because of its higher performance.

\subsubsection{Using Variables from ERA-I}

Based on the previous results, three AM structures were selected: 1 level of analogy with 8 (1~x~8) or 12 predictors (1~x~12), and 2 levels with 6 predictors (2~x~6) (Sect. \ref{experiments}). Two optimizations were performed by structure and catchment. The structure with two levels of analogy (2~x~6) turned out to be simplified by the GAs to a single level of analogy (1~x~6) for several catchments. Consequently, this structure resulted in lower accuracy as fewer predictors were used. Therefore, only structures with a single level of analogy (1~x~8 and 1~x~12) are further analyzed here. 


\begin{figure}[H]
	\vspace{-1cm}
	\noindent\makebox[\textwidth]{
		\includegraphics[width=180mm]{figures/multiple-variables-era-i.pdf}
	}
	\vspace{-0.8cm}
	\caption{Selected variables (see Table \ref{list_variables} for the variables abbreviations) from ERA-I for the 1~x~8 and 1~x~12 structures for the different catchments. The colors represent the analogy criteria, and the size of the dots is proportional to the weight given to the predictor within the range [0.02, 0.2]. Variables that were never selected with a weight equal to or larger than 0.05 are not represented.}
	\label{fig_multiple_variables_erai}
\end{figure}

\begin{figure}[H]
	\noindent\makebox[\textwidth]{
		\includegraphics[width=160mm]{figures/multiple-variables-era-i-summary.pdf}
	}
	\caption{Statistics of the 30 most selected variables from ERA-I for the 1~x~8 and 1~x~12 structures for the different catchments (100 optimizations) along with the analogy criteria, the temporal window (30 = next day at 06~UTC; some radiation variables were considered at 15~UTC), and the spatial windows (longitudes and latitudes). The extent of Switzerland is shown in gray on the plots of the spatial windows.}
	\label{fig_stats_params_erai}
\end{figure}

%\FloatBarrier

Figure \ref{fig_multiple_variables_erai} shows the different variables selected for each catchment along with the analogy criteria (color) and the weights (size). Figure \ref{fig_stats_params_erai} synthesizes the 30 most often selected variables and the associated analogy criteria, temporal windows, and spatial windows across catchments. These results again show a strong dominance of the $S_{0}$, $S_{1}$, and $S_{2}$ analogy criteria, the others being only rarely selected, including RMSD. $S_{0}$ is most often selected. The properties of $S_{0}$ are further discussed in Sect. \ref{discussion}.  

Vertical velocity (W) at 700~hPa (and sometimes at 600 or 800~hPa) is the most frequently selected variable, also for the catchments that previously selected another best single variable (Sect. \ref{best_single}). Those with higher elevations and located in the southern part of the country additionally selected W at 500~hPa or even higher.

The surface solar radiation downward (SSRD) is the second most selected variable and is mainly relevant when compared in terms of gradients ($S_{1}$) rather than absolute values. Other radiation variables occupy the fourth and fifth ranks, such as surface thermal radiation downwards (STRD) and surface net thermal radiation (STR). These are mainly relevant when compared in terms of absolute values ($S_{0}$), although there is a non-negligible representation of the $S_{1}$ criteria (see discussion on radiation variables in Sect. \ref{discussion}).

CAPE is the third most selected variable, and the total column water (TCW) is the sixth variable. In the ninth position comes the meridional wind at 10~m, but using $S_{1}$ or even $S_{2}$. The derivative of the wind can be informative on the location of frontal systems and convergence or divergence zones. Then comes the meridional wind on the PV level. The 2~m temperature has the 12th position and is compared in terms of gradients ($S_{1}$), which can reflect the position of fronts. Follows the geopotential height (Z) at 700 and 600~hPa compared primarily using the second derivatives of the fields ($S_{2}$). The curvature of the geopotential height helps to identify and characterize synoptic-scale features, such as ridges and troughs in the atmosphere. A bit further down on the list, SLP is also compared in terms of its second derivative. Other variables such as RH, PV, D, and U also populate the 30 best variables.

The optimal spatial windows (Figure \ref{fig_stats_params_erai}) cover Switzerland most of the time, with different extents depending on the variables. For example, while the medians of the optimal domains for W and CAPE are slightly larger than Switzerland, PV is here considered over a larger domain. The 2m temperature (T2m) is characterized by unusual longitudinally extended domains, with the main body in southern Switzerland extending to the northern Mediterranean. Thus, it likely represents information at a synoptic scale, such as the location of fronts, rather than local conditions. Note that SST was also in the pool of potential variables, but has never been selected as relevant.

The optimal temporal windows (time of day) show substantial variability between the predictor variables. At the lower end of the range is TCW, which is considered better at the beginning of the precipitation accumulation period (06~UTC). The top of the range (06~UTC the next day, corresponding to the end of the accumulation period) was favored by the divergence (D at 285\degree K) and some low-level W (W900 and W950) or Z (Z900). It should be noted here that the radiation variables used were cumulative variables that were not decomposed prior to the analysis. Therefore, most of the selected temporal windows correspond to the beginning of the accumulation period, i.e., 15~UTC.


\subsubsection{Using Variables from ERA5}

A similar experiment has been carried out using ERA5 and a single method structure (1~x~12). ERA5 has been used at a 3-hourly time step, which may be more relevant than 6-hourly when considering radiation variables, and at a 0.5\degree\ spatial resolution. The potential analogy criteria were limited to $S_{0}$, $S_{1}$ and $S_{2}$ and the spatial domains were slightly reduced (latitudes=[39, 55], longitudes=[-4, 20]). If previously the weights could be null for a predictor, a minimum of 0.01 was enforced here to force the GAs to select a relevant predictor. Finally, some predictors, often selected in the previous experiment, were forced: W700 (with $S_{0}$ criterion), CAPE (with $S_{0}$ criterion), TCW (with $S_{0}$ or $S_{1}$ criteria); leaving nine predictors unconstrained.

In addition, only the variables found relevant when using ERA-I were selected as potential predictors, thus decreasing the pool of variables. Also, potential temperature levels and PV levels were not considered further. However, cloud cover variables were added to the potential predictors to assess whether the radiation variables served as a proxy for cloud cover. Therefore, this experiment should not be considered a complete exploration of ERA5 as it builds on the results obtained for ERA-I.


\begin{figure}[H]
	\vspace{-1cm}
	\noindent\makebox[\textwidth]{
		\includegraphics[width=180mm]{figures/multiple-variables-era5.pdf}
	}
	\vspace{-0.8cm}
	\caption{Selected variables (see Table \ref{list_variables} for the variables abbreviations) from ERA5 for the 1~x~12 structure for the different catchments. The variables that were forced into the AM are marked with a rectangle. The colors represent the analogy criteria, and the size of the dots is proportional to the weight given to the predictor within the range [0.02, 0.2]. Variables that were never selected with a weight equal to or larger than 0.05 are not represented.}
	\label{fig_multiple_variables_era5}
\end{figure}

\begin{figure}[H]
	\noindent\makebox[\textwidth]{
		\includegraphics[width=160mm]{figures/multiple-variables-era5-summary.pdf}
	}
	\caption{Statistics of the 30 most selected variables from ERA5 for the 1~x~12 structure for the different catchments (50 optimizations) along with the analogy criteria, the temporal window (30 = next day at 06~UTC), and the spatial windows (longitudes and latitudes). The extent of Switzerland is shown in gray on the plots of the spatial windows.}
	\label{fig_stats_params_era5}
\end{figure}

%\FloatBarrier

The selected variables from ERA5 are shown in Figures \ref{fig_multiple_variables_era5} and \ref{fig_stats_params_era5}. When compared with the ERA-I results, TCW gained importance, as it was the most selected variable here. Similarly, the relative humidity at 1000 and 850~hPa increased in importance as if its relevance improved in ERA5. There were also changes in the radiation variables, with the added top (top-of-atmosphere) net thermal radiation (TTR) taking the fourth slot and being completed by other ones in the top 30 variables: top net solar radiation (TSR), surface latent heat flux (SLHF), surface net thermal radiation (STR), surface solar radiation downwards (SSRD), and surface net solar radiation (SSR). These variables are likely highly correlated, and the selection could be reduced. It can also be noted that these variables are still often considered in terms of gradient (using $S_{1}$), even though cloud cover variables were made available (see discussion on radiation variables in Sect. \ref{discussion}). As for cloud cover variables, different ones were selected in the top 30: low cloud cover (LCC) and cloud cover (CC) at 600, 1000, and 500~hPa. Although LCC was most often considered in terms of gradients, the absolute values of the other cloud cover variables were mostly selected. The importance of low-level PV also increased compared to ERA-I. Conversely, the geopotential height was only selected at 500~hPa in the top 30 predictors, SLP is no longer among the best, and the presence of the divergence variables also decreased.

The optimal spatial domains are comparable with those selected for ERA-I, including the 2-meter temperature extension to the south. Regarding the temporal windows, TCW is again mainly selected between 6 and 12~UTC, and RH at different times of the day. PV is often selected at the end of the day, along with W at 1000~hPa, the surface latent heat flux (SLHF), and the 2-meter temperature (T2m). The other variables are mainly selected during the daytime.


\subsection{Accuracy of the optimized methods}
\label{skill_score}

To assess the relevance of the methods optimized in this work, their accuracy has been compared to the benchmark methods (Sect. \ref{ams}). Figure \ref{fig_scores} shows the CRPS skill score and the Brier skill scores for different thresholds (1~mm, 10~mm, 50~mm) using the simplest RM1 method (for the CP) as reference. The best optimization result per catchment was selected based on the VP score. The scores for the test period (TP) were then calculated from unseen data for these selected parameter sets.


\begin{figure}[hbtp]
	\noindent\makebox[\textwidth]{
		\includegraphics[width=130mm]{figures/scores-all-methods.pdf}
	}
	\caption{Skill scores (CRPSS and Brier skill score) of the different benchmark and optimized methods on the calibration, validation, and test periods for the 25 catchments. The skill scores use the RM1 method on the CP as a reference. An LxP code represents the structures, with L being the number of levels of analogy and P being the number of predictors per level.}
	\label{fig_scores}
\end{figure}

\begin{figure}[hbt]
	\noindent\makebox[\textwidth]{
		\includegraphics[width=130mm]{figures/rank_histogram.pdf}
	}
	\caption{Rank histogram for the prediction by the optimized AM for the Ergolz catchment on both the calibration and test periods. The frequencies were averaged over a boostrapping of 1000 realizations to smooth out the effect of the random rank attribution of the zero precipitation cases.}
	\label{rank_histogram}
\end{figure}

The skill scores are shown for the first single variable selection from ERA-I (ERA-I GAS 1x1), and the full optimizations using ERA-I (ERA-I GAS 1x8, 1x12) or ERA5 (ERA5 GAS 1x12). One can see in Fig. \ref{fig_scores} that the selection of a single best variable (GAS 1x1) shows similar accuracy to the RM1 method. Obviously, the skill of a single variable remains lower than that of more complex AMs. The other optimized methods (GAs 1x8 or 1x12) show a higher CRPSS than the benchmark methods. Thus, despite having a single level of analogy, they outperform complex stepwise AMs in terms of CRPS. Brier skill scores for the prediction of the precipitation occurrence (threshold of 1~mm) of the optimized methods show values similar to those of RM6 when ERA-I is used and some further improvements when ERA5 is used. Brier skill scores of the optimized methods show similar skill to the best benchmark methods for a threshold of 10~mm, but lower values for a threshold of 50~mm. This can result from either an underestimation or an overestimation of the prediction. The GAs optimized the methods by minimizing the CRPS only, and a combined objective function that also accounts for the Brier score, for example, could be used instead to improve other properties of the resulting AMs. The gain obtained by using ERA5 instead of ERA-I may be due to higher spatial and temporal resolutions or better variables \cite{Horton2021}. 

Some differences can be observed between the three splits (CP, VP, TP), also for the benchmark methods. However, there is no clear trend, and the distributions remain relatively close. These differences can have multiple origins: the presence of stronger precipitation events in some splits, inhomogeneities in the quality of the predictor variables, or just natural variability. The three splits of the method optimized with ERA5 provide very similar results, which can be due to its higher quality, the variables selected, or just luck. Anyway, the selection of the predictor variables and the analogy criteria by GAs, along with all other parameters, provides AMs that prove relevant and consistent among different periods. No overfitting from the GAs can be observed.

Rank histograms have been computed for some catchments. Figure \ref{rank_histogram} shows such a plot for the Ergolz catchment. Other catchments show similar results, i.e. that the prediction by AMs tends to be over-dispersive without presenting a clear bias. This observation is not specific to these results, but is a common behaviour of AMs. 

An additional experiment has been attempted by forcing the predictor variables (along with their vertical level and their time) and the analogy criteria and letting the GAs optimize the weights between these variables, along with the spatial domains. To this end, 26 of the most commonly selected ERA5 variables were provided to the optimizer, organized in a single level of analogy (1x26). The results are shown in Appendix C. This approach did not provide the best accuracy (not shown), which can be due to non-optimal choices made to homogenize the vertical levels or times of the day, for example. In addition, this approach is not computationally efficient, as it requires loading variables that barely play a role in the selection of analog situations. Therefore, we do not recommend using this strategy.

\begin{figure}[hbtp]
	\noindent\makebox[\textwidth]{
		\includegraphics[width=120mm]{figures/events.pdf}
	}
	\caption{Illustration of predictions for the strongest precipitation event of the test period for several catchments. The predictions provided by the AMs are illustrated by their whole range as well as some quantiles often considered in operational forecasting.}
	\label{fig_events}
\end{figure}

The predictions provided by the optimized AMs for the strongest precipitation event of the test period are illustrated for some catchments in Fig. \ref{fig_events}. While most of these heavy precipitation events were captured satisfactorily by the optimized AMs, few were underestimated in some catchments as shown in Fig. \ref{fig_events} (bottom), where the two worst predictions are shown.



\section{Discussion}
\label{discussion}

The primary objective of this study was to assess the relevance of GAs in selecting input variables for AMs. The results demonstrated that GAs could identify pertinent predictors and analogy criteria. However, caution is due when extrapolating the use of these selected predictors to different contexts, as their applicability may not be universally optimal. In fact, the compilation of potential variables must be tailored to the specific requirements of the AM application. For example, in forecasting applications, only meteorological variables deemed reliably predicted should be included. In the context of climate impact studies, the selection is constrained by the limited availability of meteorological variables compared to the extensive output provided by reanalysis and NWP models. Furthermore, it is crucial to exercise discretion in selecting variables that exhibit a causal relationship with the predictand of interest and avoid undesirable covariability. Essentially, adapting the pool of potential variables to the application at hand is fundamental for a robust use of the optimized AM.

Radiation variables were often selected as relevant predictors. When using ERA-I, SSRD is the second most selected variable, and STRD and STR are the fourth and fifth. When using ERA5, TTR is the fourth most important variable. As these variables were selected so often, they did provide useful information for precipitation prediction, but their role is not easily interpretable. Hereafter, we propose some hypotheses about the information that can potentially be retrieved from these variables. First, STR values for days with high precipitation values show positive anomalies, meaning that the long-wave radiation from the atmosphere towards the surface is anomalously high (vertical fluxes are positive downward). Thermal radiation emitted by clouds and the atmosphere contributes to the downward STR. It is possible that the thermal radiation flux towards the surface is increased due to a high concentration of water vapor in the lower atmosphere and/or the presence of low clouds (with a higher cloud base temperature). Therefore, it can be used as a proxy for the presence of low clouds. Low clouds can interact with the topography, and this interaction might not be reflected in the vertical motion in ERA-I due to the relatively coarse spatial resolution of the orography in the reanalysis. The information from STR would then compensate for missing local processes at some locations, which potentially have a better representation in ERA5.

Then, SSRD was selected as a relevant predictor, but with the analogy criteria comparing the gradients rather than the absolute values, meaning that the pattern of SSRD matters more than its values. Gradients in SSRD could be an indication of the presence of fronts or thunderstorm clouds. Finally, in ERA-5, TTR anomalies are selected. They can be a proxy for high cloud tops with lower temperatures and, therefore, might provide information on the cloud thickness. Further research is needed to explore these hypotheses.

The triplet $S_{0}$, $S_{1}$ and $S_{2}$ dominate the selection of analogy criteria. The $S_{1}$ score originally developed by \citeA{Teweles1954} to verify prognostic charts was then used because it penalizes forecasters who tend to be overly conservative by forecasting weak systems too often. The rationale behind this lies in the denominator, which is determined by the sum of the maximum gradients of either the forecast or the observation. Consequently, forecasting a weaker system incurs a greater penalty than forecasting a stronger one. However, it should be noted that this approach may lead to the opposite effect, as forecasters may find it safer to predict stronger systems with larger gradients, thereby inflating the denominator \cite{Thompson1972}. This can be transposed to the AM, where stronger gradients in Z from analog situations are preferred over weaker ones.

The $S_{0}$ and $S_{2}$ criteria share a key characteristic with $S_{1}$ by imposing heavier penalties on weaker fields. Consequently, the analog selection based on $S_{0}$, $S_{1}$, and $S_{2}$ exhibits asymmetry, favoring the selection of analog fields close to the target but tending towards greater rather than weaker values (see Appendix C). The inherent asymmetry of $S_{0}$, $S_{1}$, and $S_{2}$ proves advantageous for prediction. Optimal analog situations are skewed toward being slightly stronger than weaker. Considering that the CRPS is strongly influenced by heavy precipitation events, this suggests a hypothesis: given the potential underrepresentation of large precipitation events in the archive, AMs benefit from selecting stronger predictor fields, often associated with higher precipitation. This selection bias may function as a compensatory mechanism for the underrepresentation of intense precipitation events. These assumptions would need to be further investigated.


\section{Conclusions}
\label{conclusions}

The objective of the work was to assess the ability of GAs to select the input variables of the analog method along with the analogy criteria. The experiment was successful, as the selected predictors provided better accuracy (in terms of CRPS that was used as the objective function for the optimizations) than the benchmark methods, without overfitting. In addition, most of the selected variables can be related to the meteorological processes involved in precipitation generation. For example, among the most selected variables are: the vertical velocity (W) at 700~hPa (along with other levels), the total column water (TCW), the convective available potential energy (CAPE), radiation variables, the potential vorticity (PV), the relative humidity (RH), cloud cover variables, wind components, the geopotential height, air temperature, and the divergence.

The selection of analogy criteria also proved fruitful, as there were clear trends toward a dominant criterion for a given variable. The unexpected result was the success of the criterion $S_{0}$, inspired by the Teweles-Wobus criterion. This new $S_{0}$ turned out to be the most often selected analogy criterion for the characterization of Euclidean distances. Three analogy criteria were most often selected and all are derived from the Teweles-Wobus criterion; one is based on the raw point values, another on the gradients, and the third on the second derivative of the fields. All of them are normalized by the sum of the largest point(pair)-wise values from the target or the candidate fields. This normalization makes the criteria asymmetrical, so that higher values are preferred to lower ones. These new criteria should be further investigated and could be used in classic AMs.

Another unexpected result is the preferred structure for analog methods. While most benchmark methods build on a stepwise selection of predictors with successive levels of analogy subsampling from the previous one by using different predictors, here, the GAs preferred a flatter structure, mainly with a single level of analogy, but more variables. The benchmark methods most often start with selecting candidate analogs using the geopotential height and then narrowing down the selection using vertical velocity or moisture variables. A primary difference with the benchmark methods is that the variables are standardized here and weights are used (and optimized) to combine them in a given level of analogy. These two elements make the combination of variables with different value ranges easier. However, it cannot be excluded that deeper structures can provide better results, but that GAs did not find these solutions.

Such optimization is computationally intensive. The new GPU-based computations brought notable time improvement, particularly for high-resolution data. Other approaches could be considered to decrease the computation time, such as a faster exploration of the dataset using a smaller period for data pre-screening, or the division of the whole period into smaller batches. An alternative could be to reduce the number of days with small precipitation amounts, as they have a small impact on the CRPS, while weighting their contributions by using a weighted CRPS approach.

This work opens new perspectives for input variable selection in the context of the analog method. While the variables selected in these experiments may not be transferable to other contexts, the approach was proven successful and can be applied to other datasets. The potential variables must be chosen wisely with respect to the intended application. Such an approach can, for example, be used to select the relevant variables to predict precipitation for a new location, or as a data mining technique to explore a dataset to predict a new predictand of interest. Using GAs to perform input variables selection can be applied to other data-driven methods, opening perspectives for a broad range of applications.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Optional Appendix goes here
%
% The \appendix command resets counters and redefines section heads
%

\FloatBarrier

\appendix

\section{GPU Implementation and Benchmark}

Several GPU implementations were tested, with the most successful aiming to reduce the data copy to the device while increasing the load of parallel processing. It consisted in copying the predictor data to the device and calling the kernel\footnote{A kernel is a numerical function executed in parallel on the GPU.} for every target date, thus assessing all candidates for that target date in one call. The main benefit of this variant is that it allows overlapping -- using streams -- the calculation of the analogy criteria on the GPU and other calculations on the CPU, such as the extraction of the indices corresponding to the candidate dates (using a temporal moving window of 120~days) and the sorting of the resulting analogy criteria.

Threads on the GPU are organized in dynamically defined blocks with a size from 32 to 1024 threads. Here, every candidate date is assigned to a different block, with internal loops for cases where the number of grid points is greater than the number of threads in the block. All analogy criteria need a reduction step to synthesize a two-dimensional array into a single value. The reduction is part of the analogy criteria calculation and is thus also done on the GPU. The threads are organized in groups of 32, called warps, which are synchronous and can access each other's registers. The reduction on the device was performed with an efficient warp-based reduction using the CUDA shuffle instruction. Different block sizes were evaluated and the size of 64~threads was identified as optimal as it leaves fewer threads inactive during the reduction. Access to the GPU's global memory has also been kept to a minimum because of its higher latency.

The Google benchmark library was used to assess the computing time of different AM structures -- single or two levels of analogy and up to four predictors per level -- along with various grid sizes. Figure \ref{cuda} shows the results for the analogy criterion $S_{1}$, with gradients pre-processed using CPUs only (counted in the total time). The other analogy criteria showed similar results. The task consisted of extracting analogs for 32 years using the other 31 years as archives for candidate situations within a 120-days temporal window. It makes a total of $43.5\cdot10^6$ field comparisons per predictor of the first level of analogy.

\begin{figure}[hbt]
	\noindent\includegraphics[width=130mm]{figures/cuda-timing.pdf}
	\caption{Computing time for the extraction of analogs over 32 years using the $S_{1}$ criteria for different grid sizes and various structures of AMs. An LxP code represents the structures, with L being the number of levels of analogy and P being the number of predictors per level. Time is given for using (s) standard CPUs and (c) CUDA on GPUs (NVIDIA GeForce RTX 2080). Note the logarithmic axes.}
	\label{cuda}
\end{figure}

The experiment was carried out on the UBELIX cluster of the University of Bern, using the same node for the whole benchmark and processing on a single NVIDIA GeForce RTX 2080 graphics card. The CPU processing -- using the linear algebra library Eigen 3 \cite{Guennebaud2010} -- was done on a single thread. Although AtmoSwing can parallelize the calculation of the analogy criteria on multiple CPU threads, it uses a single thread for this task when optimizing with GAs because it parallelizes the evaluation of the different individuals on multiple threads. With GPUs, it still assesses the individuals on multiple CPU threads, each of them being able to use a different GPU device to calculate the analogy criteria. It is thus parallelizing both on CPUs and GPUs.

The benchmark (Fig. \ref{cuda}) shows that GPU computations are systematically faster than those on the CPU, and this difference increases with the number of grid points. The GPU computations were 13 times faster on average and up to 38 times faster (5.2~sec instead of 3.3~min) when using 2048 points. NWP model outputs and reanalyses show an increase in spatial resolution; therefore, the impact on the computation time will become increasingly important. When using CPU only, adding a predictor in the first level of analogy has a much higher impact on time than adding a second level of analogy. It is explained by the fact that it needs to process the analogy criteria for the whole archive for each predictor of the first level of analogy, while the second level has only a few candidate situations to assess.



\section{Performance of the Mutation Operators}

As suggested in \citeA{Horton2017a}, five variants of the mutation operator were used in parallel optimizations:

\begin{enumerate}
	\item Chromosome of adaptive search radius \cite{Horton2017a}
	\item Multiscale mutation \cite{Horton2017a}
	\item Non-uniform mutation ($p_{mut}$=0.1, $G_{m,r}$=50, $w$=0.1)
	\item Non-uniform mutation ($p_{mut}$=0.1, $G_{m,r}$=100, $w$=0.1)
	\item Non-uniform mutation ($p_{mut}$=0.2, $G_{m,r}$=100, $w$=0.1)
\end{enumerate}

where $p_{mut}$ is the mutation probability, $G_{m,r}$ is the maximum number of generations (G) during which the magnitude of the research varies, and $w$ is a threshold chosen to maintain a minimum search magnitude when $G>G_{m,r}$.

Figure \ref{fig_mutation_operators_perfs} shows the performance of these five mutation operators for different AM structures and the different catchments considered in Sect. \ref{structures}. Overall, the chromosome of adaptive search radius has a success rate of 76.25\% in calibration and 62.5\% in validation, the multiscale mutation 7.5\%, and 8.75\% respectively, and the non-uniform mutation with its different options: (3) 11.25\% and 10\%, (4) 11.25\% and 21.25\%, and (5) 1.25\% and 2.5\% respectively.

\begin{figure}[hbt]
	\noindent\makebox[\textwidth]{
		\includegraphics[width=170mm]{figures/gas-configs-ams-structures.pdf}
	}
	\caption{Performance of the five mutation operators (Sect. \ref{gas}) for different AM structures and the different catchments considered in Sect. \ref{structures}. The values represent the number of optimizations for one mutation operator that resulted in the best performing AM. Results are shown for both calibration and validation. When multiple operators obtain the same accuracy, they all get a point.}
	\label{fig_mutation_operators_perfs}
\end{figure}

Thus, it is quite clear that the chromosome of adaptive search radius obtains the best results, all the more so with more complex structures, i.e., more predictor variables. Although its success rate decreases slightly in validation, it remains much larger than the other options. The non-uniform mutation shows notable variability of performance depending on its options.

\FloatBarrier

\section{Analysis of the new $S_{0}$ Criteria}

The $S_{0}$ and $S_{2}$ criteria have the same characteristic as $S_{1}$, i.e., they penalize weaker fields more heavily. Consider a field F1 with values 50\% lower than the target field (F), and another one, F2, with values 50\% higher. Then, $S_{0}(F, F1) = 50$ and $S_{0}(F, F2) = 33.3$ while the absolute differences between the target (F) and F1 or F2 are equal. F2 will then be selected as a better analog. To get the same $S_{0}$ value, F2 would need to double the target field values. The consequence is that the selection of analogs based on $S_{0}$, $S_{1}$ and $S_{2}$ is not symmetrical, and these criteria tend to select fields that are close to the reference but preferably stronger than weaker. 

To further investigate the characteristics of $S_{0}$, we considered a variation named here $S_{0obs}$ that uses the observation (here, target situation) values only for the denominator and not the maximum between observation and forecast (here, candidate analog). It is then similar to MAPE (Mean Absolute Percent Error) and is symmetrical. We performed a classic calibration of a simple AM using only W700 with (1) the $S_{0}$ criteria, (2) the RMSD criteria, and (3) the $S_{0obs}$ criteria. The calibration was performed separately for each setup. Using RMSD deteriorates the accuracy by 8.7\% on average, and $S_{0obs}$ also deteriorates the accuracy by 9.8\%. Thus, the asymmetrical property of $S_{0}$ is beneficial for the prediction. 

We then considered the RM3 benchmark method and performed a classic calibration for the 25 catchments by replacing one or the other criterion. When using $S_{1obs}$ ($S_{1}$ normalized by the gradients of the observations only) instead of $S_{1}$ for Z, the accuracy deteriorates by 4.8\% on average. However, when replacing the RMSD of the second level of analogy (MI) with $S_{0}$, there is a slight performance loss of 0.5\%. As there is strong conditioning by the first level of analogy that provides the sample of candidate analog dates to be subsampled on moisture variables, the criterion of the second level of analogy has a lower impact.

The asymmetrical properties of $S_{0}$, $S_{1}$, and $S_{2}$ are beneficial for the prediction. Analog situations are best considered a bit stronger than weaker while being close to the target situation. The CRPS is mainly sensitive to high precipitation values, even more so when the precipitation is not transformed \cite<see>[for precipitation transformation]{Bontron2004}. Thus, one hypothesis is that large precipitation events being underrepresented in the archive, AMs are better off selecting stronger predictor fields, often associated with higher precipitation. It might then play a role of bias compensation for underrepresented high precipitation events. The reason for such behavior should be further investigated.


\section{An Attempt to Constrain the Algorithms}

An additional experiment has been attempted by pre-selecting the predictor variables (along with their vertical level and their time) and the analogy criteria and letting the GAs optimize the weights between these variables, along with the spatial domains. To this end, 26 of the most frequently selected ERA5 variables were provided to the optimizer, organized in a single level of analogy. The results are shown in Figure \ref{fig_variables_homogen} and depict high weight values for W at 600 and 700~hPa. Surprisingly, Z700 based on $S_{2}$ also has relatively high weight values. However, these results turned out to be lower in terms of accuracy compared to the fully optimized methods.


\begin{figure}[H]
	\noindent\makebox[\textwidth]{
		\includegraphics[width=180mm]{figures/preselected-variables-era5.pdf}
	}
	\vspace{-0.8cm}
	\caption{Results of the optimization with preselected 26 variables for the different catchments. (top) The colors represent the analogy criteria, and the size of the dots is proportional to the weight given to the predictor within the range [0.01, 0.2]. (bottom) Boxplot of the weight values for the different variables.}
	\label{fig_variables_homogen}
\end{figure}



\FloatBarrier

\section*{Open Research}
The precipitation dataset, RhiresD \cite{MeteoSwiss2021}, used as predictand in the study, is available upon request at MeteoSwiss (https://www.meteoswiss.admin.ch/) for research-only purposes. The catchment extents \cite{HADES} used for aggregating the precipitation can be downloaded from the Hydrological Atlas of Switzerland website (https://hydromaps.ch/). The ERA-Interim reanalysis \cite{Dee2011a} was obtained from the ECMWF Data Server at http://apps.ecmwf.int/datasets but has now been decommissioned. The Climate Forecast System Reanalysis \cite[CFSR]{CFSR} is available for download from the NCAR Research Data Archive at https://doi.org/10.5065/D69K487J. The ERA5 reanalysis \cite[Complete ERA5 global atmospheric reanalysis]{ERA5} is available for download from the Copernicus Climate Change Service at https://doi.org/10.24381/cds.143582cf. The software used, AtmoSwing \cite{Horton2019b}, is open-source (CDDL-1.0 license) and can be downloaded from GitHub at https://github.com/atmoswing/atmoswing. AtmoSwing version 2.1.2 was used in the study and the corresponding source code is available on Zenodo at https://doi.org/10.5281/zenodo.3559787.


\acknowledgments
Calculations were performed on UBELIX (http://www.id.unibe.ch/hpc), the HPC cluster at the University of Bern. The authors thank the Water Resources Research editors (editor Stefan Kollet, associate editor Jonathan J. Gourley) and three anonymous reviewers for their helpful comments.

%% ------------------------------------------------------------------------ %%
%% References and Citations

\bibliography{references}


\end{document}

